{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm up\n",
    "\n",
    "The code below showcases a convolutional network in Keras. It was designed to classify 100x100 rgb images into 10 classes.\n",
    "This network... quite frankly, it sucks. Can you guess what's the problem? Is there just one problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as L\n",
    "import keras.initializers as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = keras.models.Sequential()\n",
    "\n",
    "net.add(L.InputLayer([100, 100, 3]))\n",
    "\n",
    "net.add(L.Conv2D(filters=512, kernel_size=(3, 3), \n",
    "                 kernel_initializer=init.zeros()))\n",
    "net.add(L.Activation('relu'))\n",
    "\n",
    "net.add(L.Conv2D(filters=128, kernel_size=(3, 3), \n",
    "                 kernel_initializer=init.zeros()))\n",
    "net.add(L.Activation('relu'))\n",
    "\n",
    "net.add(L.Conv2D(filters=32, kernel_size=(3, 3), \n",
    "                 kernel_initializer=init.zeros()))\n",
    "net.add(L.Activation('relu'))\n",
    "\n",
    "net.add(L.MaxPool2D(pool_size=(6, 6)))\n",
    "\n",
    "net.add(L.Conv2D(filters=8, kernel_size=(10, 10), \n",
    "                 kernel_initializer=init.RandomNormal(), padding='same'))\n",
    "net.add(L.Activation('relu'))\n",
    "\n",
    "\n",
    "net.add(L.Conv2D(filters=8, kernel_size=(10, 10), \n",
    "                 kernel_initializer=init.RandomNormal(), padding='same'))\n",
    "net.add(L.Activation('relu'))\n",
    "\n",
    "net.add(L.MaxPool2D(pool_size=(3, 3)))\n",
    "\n",
    "net.add(L.Flatten()) # convert 3d tensor to a vector of features\n",
    "\n",
    "net.add(L.Dense(units=512))\n",
    "net.add(L.Activation('softmax'))\n",
    "\n",
    "net.add(L.Dropout(rate=0.5))\n",
    "\n",
    "net.add(L.Dense(units=512))\n",
    "net.add(L.Activation('softmax'))\n",
    "\n",
    "net.add(L.Dense(units=10))\n",
    "net.add(L.Activation('sigmoid'))\n",
    "net.add(L.Dropout(rate=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Conv2D](https://keras.io/layers/convolutional/#conv2d) - performs convolution:\n",
    "    * filters: number of output channels;\n",
    "    * kernel_size: an integer or tuple/list of 2 integers, specifying the width and height of the 2D convolution window;\n",
    "    * padding: padding=\"same\" adds zero padding to the input, so that the output has the same width and height, padding='valid' performs convolution only in locations where kernel and the input fully overlap;\n",
    "    * activation: \"relu\", \"tanh\", etc.\n",
    "    * input_shape: shape of input.\n",
    "* [MaxPooling2D](https://keras.io/layers/pooling/#maxpooling2d) - performs 2D max pooling.\n",
    "* [Flatten](https://keras.io/layers/core/#flatten) - flattens the input, does not affect the batch size.\n",
    "* [Dense](https://keras.io/layers/core/#dense) - fully-connected layer.\n",
    "    * Activation - applies an activation function.\n",
    "* [LeakyReLU](https://keras.io/layers/advanced-activations/#leakyrelu) - applies leaky relu activation.\n",
    "* [Dropout](https://keras.io/layers/core/#dropout) - applies dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book of grudges\n",
    "* zero init for weights will cause symmetry effect\n",
    "* Too many filters for first 3x3 convolution - will lead to enormous matrix while there's just not enough relevant combinations of 3x3 images (overkill).\n",
    "* Usually the further you go, the more filters you need.\n",
    "* large filters (10x10 is generally a bad pactice, and you definitely need more than 10 of them\n",
    "* the second of 10x10 convolution gets 8x6x6 image as input, so it's technically unable to perform such convolution.\n",
    "* Softmax nonlinearity effectively makes only 1 or a few neurons from the entire layer to \"fire\", rendering 512-neuron layer almost useless. Softmax at the output layer is okay though\n",
    "* Dropout after probability prediciton is just lame. A few random classes get probability of 0, so your probabilities no longer sum to 1 and crossentropy goes -inf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you have to train a new Convolutional Neural Network from scratch for the classification of images.\n",
    "\n",
    "1. For this we will use the Keras library.\n",
    "2. The aim is to achieve 99% accuracy (on validation/test set) the MNIST dataset http://yann.lecun.com/exdb/mnist/.\n",
    "3. We have provided a basic Keras implementation of a CNN.\n",
    "4. You are allowed to do whatever you want (except copy pasting) with the network as long as it is explained in your report.\n",
    "5. Feel free to change the architecture of the network as well as parameters (e.g. learning rate, kernel sizes, ...).\n",
    "6. You can try to guess parameters manually of you want, just make sure that it performs better than 99% on the validation set.\n",
    "7. Sketch the final network architecture in your report.\n",
    "8. Make sure you train the network on the GPU, otherwise it will be too slow.\n",
    "9. Explain the plots: learning curve, accuracy wrt epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 16:41:04.092123: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 16:41:04.231440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-06 16:41:04.231454: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-06 16:41:04.897653: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 16:41:04.897694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 16:41:04.897700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, Dense , MaxPool2D, Flatten\n",
    "from keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,t_test) = datasets.mnist.load_data()\n",
    "x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,2))\n",
    "plt.imshow(x_train[104])\n",
    "y_train[104]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Sequential(\n",
    "    [\n",
    "        Conv2D(filters = 32, kernel_size =(3,3), activation= 'relu' ,padding = 'valid', input_shape=(28,28,3) ),\n",
    "        MaxPool2D(pool_size= (2,2), strides = 2),\n",
    "        Conv2D(filters = 64, kernel_size =(3,3), activation= 'relu'),\n",
    "        MaxPool2D(pool_size= (2,2), strides = 2),\n",
    "        # Conv2D(filters = 128, kernel_size =(3,3), activation= 'relu'),\n",
    "        # MaxPool2D(pool_size= (2,2), strides = 2),\n",
    "        # Conv2D(filters = 64, kernel_size =(3,3), activation= 'relu'),\n",
    "        Flatten(),\n",
    "        Dense(units=10, activation ='softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,402\n",
      "Trainable params: 35,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss = 'categorical_crossentropy',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name='conv2d_7_input'), name='conv2d_7_input', description=\"created by layer 'conv2d_7_input'\"), but it was called on an input with incompatible shape (32, 28, 28).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"conv2d_7\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (32, 28, 28)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(32, 28, 28), dtype=uint8)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mx_train,y \u001b[39m=\u001b[39;49m y_train ,validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filezajqmdw9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/user/.local/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"conv2d_7\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (32, 28, 28)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(32, 28, 28), dtype=uint8)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "Model.fit(x=x_train,y = y_train ,validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
